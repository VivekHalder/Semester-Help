# JUETCECHATBOT

# University Electronics Q\&A Chatbot (RAG-based)

A full-stack **Retrieval-Augmented Generation (RAG)** chatbot system built for university-level electronics students. This application enables students to query topics from curated textbooks and get accurate, contextual answers powered by **OpenAI's LLM**, FAISS-based vector retrieval, and CrossEncoder reranking.

---

## âœ¨ What is RAG?

**Retrieval-Augmented Generation (RAG)** is an architecture that enhances language models by combining retrieval-based information with generative capabilities.

* **Retrieval**: Relevant text chunks are fetched from a knowledge base (e.g., textbooks) using vector similarity.
* **Augmentation**: These chunks are passed along with the user query to an LLM.
* **Generation**: The LLM generates a response **grounded** in the retrieved context.

### Why RAG over pure LLM?

| Feature                           | Plain LLM | RAG + LLM |
| --------------------------------- | --------- | --------- |
| Real-time domain knowledge        | âŒ         | âœ…         |
| Faithful, grounded answers        | âŒ         | âœ…         |
| Small context window optimization | âŒ         | âœ…         |
| Lower hallucination risk          | âŒ         | âœ…         |

---

## ğŸ” Use Case

* Designed to help students understand microprocessors and electronics concepts by asking natural language questions.
* Only **admin-curated PDFs** are vectorized (students don't upload searchable PDFs).
* Useful for universities to integrate an intelligent, syllabus-aligned teaching assistant.

---

## ğŸš€ Tech Stack

### Backend

* **FastAPI** â€“ Web framework for serving chat API and user management
* **MongoDB** â€“ User info and persistent chat history
* **FAISS** â€“ Vector search from pre-uploaded PDF chunks
* **HuggingFace Transformers** â€“ Sentence embedding (`all-MiniLM-L6-v2`)
* **CrossEncoder** â€“ For reranking search results
* **OpenAI GPT-4 / GPT-3.5** â€“ For generating final answers
* **Tiktoken** â€“ Token counting to avoid overflow

### Frontend

* **React.js** â€“ Frontend UI
* **TailwindCSS** â€“ Styling
* **Axios** â€“ API communication

---

## âš™ï¸ Installation

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/ju-ece-chatbot.git
cd ju-ece-chatbot
```

### 2. Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
cd client
npm install
npm run dev
```

---

## ğŸ” Features

* âœ… User registration & login (JWT-authenticated)
* âœ… Interactive chat interface with LLM-powered answers
* âœ… Chat memory using MongoDB
* âœ… PDF upload (admin only) + automatic vectorization
* âœ… Image-based diagram support for context
* âœ… Chat export (PDF/JSON)
* âœ… Usage analytics
* âœ… Profile update functionality
* âœ… Academic flow: users select **year**, **semester**, and **subject** before chatting

---

## ğŸ’¡ How it Works

1. **User logs in**, selects academic details (year, sem, subject)
2. **Asks a question** from the interactive chat UI
3. **Query optimized** to improve search quality
4. **Vector store searched** using FAISS + HuggingFace embeddings
5. **CrossEncoder reranks** the results
6. **Top-ranked text chunks** passed to OpenAI LLM
7. **Answer generated** grounded in source context
8. **Images retrieved** by document name & page number
9. **Chat & academic context stored** for history/analytics

---

## ğŸ“„ Example Prompt

```
Question: Explain the working of 8085 ALU with an example
```

---

## ğŸŒ Deployment Notes

* Works locally with MongoDB
* Can be deployed with Docker, Railway, Render, or any FastAPI-friendly PaaS
* Add your OpenAI key in environment variables

---

## ğŸš« Disclaimer

This is an academic-focused demo and not suitable for medical, legal, or production-critical applications.

---

## ğŸŒŸ Credits

* OpenAI for LLMs
* HuggingFace for embeddings and rerankers
* LangChain for vector & memory wrappers
